{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f52f316",
   "metadata": {},
   "source": [
    "# RDF Creation\n",
    "\n",
    "In this document I will proceed in the pipeline by generating a file containing RDF triplets. I start from the previous file, \"IbsenStage_with_uris.json\". In this step i use `rdflib`. As explained in the main documentation, each theatre event becomes a `schema:TheaterEvent`, linked to a play (`schema:Play`) and a venue (`schema:EventVenue`).\n",
    "Where available, the script links works and venues to Wikidata URIs via `schema:sameAs`. It also adds normalized performance dates (`xsd:date`), event names, and internal IDs. If the venue’s URI isn’t available, the city’s Wikidata URI is used as a fallback (`schema:location`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc173ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4924 records…\n",
      "Processed 0\n",
      "Processed 1000\n",
      "Processed 2000\n",
      "Processed 3000\n",
      "Processed 4000\n",
      "✅ Saved 30442 triples to C:\\Users\\Cristiano (CC)\\Desktop\\Cristiano-June25\\OsloMet\\Masterstudium i bibliotek- og informasjonsvitenskap - deltid\\MBIB4140 - Metadata og interoperabilitet\\2ndre sjansen\\Ibsenstage_curated\\ibsenstage_triplets.ttl\n"
     ]
    }
   ],
   "source": [
    "import json, re, math, datetime\n",
    "from pathlib import Path\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, DCTERMS, XSD\n",
    "\n",
    "# Set the working directory and search upwards until required folder is found\n",
    "cwd = Path.cwd()\n",
    "root = cwd\n",
    "while not (root / \"Ibsenstage_staged\").exists() and root.parent != root:\n",
    "    root = root.parent\n",
    "\n",
    "# Define input and output paths\n",
    "input_path = root / \"Ibsenstage_staged\" / \"IbsenStage_with_uris.json\"\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Cannot find file: {input_path}\")\n",
    "output_dir = root / \"Ibsenstage_curated\"\n",
    "if not output_dir.exists():\n",
    "    raise FileNotFoundError(f\"Cannot find directory: {output_dir}\")\n",
    "output_path = output_dir / \"ibsenstage_triplets.ttl\"\n",
    "\n",
    "# Define namespaces for RDF\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "WD = Namespace(\"https://www.wikidata.org/entity/\")\n",
    "IBSEN = Namespace(\"https://ibsenstage.hf.uio.no/pages/\")\n",
    "\n",
    "# Initialize RDF graph and bind prefixes\n",
    "g = Graph()\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"wd\", WD)\n",
    "g.bind(\"xsd\", XSD)\n",
    "\n",
    "# Normalize dates into valid xsd:date format, or fallback to string literals\n",
    "def normalize_date(date_str):\n",
    "    if not date_str:\n",
    "        return None, None\n",
    "    s = str(date_str).strip()\n",
    "    m = re.match(r\"^(\\d{4})-(\\d{2})-(\\d{2})$\", s)\n",
    "    if m:\n",
    "        y, mo, d = map(int, m.groups())\n",
    "        try:\n",
    "            datetime.date(y, mo, d)  # Validates the date\n",
    "            return s, XSD.date\n",
    "        except ValueError:\n",
    "            return s, None\n",
    "    if re.match(r\"^\\d{4}-\\d{2}$\", s):\n",
    "        return s + \"-01\", XSD.date  # Fill missing day\n",
    "    if re.match(r\"^\\d{4}$\", s):\n",
    "        return s + \"-01-01\", XSD.date  # Fill missing month/day\n",
    "    return s, None  # Fallback to literal string\n",
    "\n",
    "# Load data from JSON\n",
    "data = json.loads(input_path.read_text(encoding=\"utf-8\"))\n",
    "print(f\"Processing {len(data)} records…\")\n",
    "\n",
    "# Loop through each record\n",
    "for i, rec in enumerate(data):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processed {i}\")\n",
    "    eid = str(rec.get(\"eventid\"))  # Unique event ID\n",
    "    wid = rec.get(\"workid\")        # Work (play) ID\n",
    "    vid = str(rec.get(\"venueid\"))  # Venue ID\n",
    "\n",
    "    # Normalize work ID\n",
    "    if isinstance(wid, (int, float)) and not math.isnan(wid):\n",
    "        wid = str(int(wid))\n",
    "    elif isinstance(wid, float) and math.isnan(wid):\n",
    "        wid = None\n",
    "    else:\n",
    "        wid = str(wid).strip() if wid else None\n",
    "\n",
    "    # Get Wikidata URI for work\n",
    "    work_ref = None\n",
    "    raw_work = rec.get(\"workURI\")\n",
    "    if raw_work:\n",
    "        qid = raw_work if raw_work.startswith(\"Q\") else raw_work.rsplit(\"/\", 1)[-1]\n",
    "        work_ref = WD[qid]\n",
    "\n",
    "    # Get Wikidata URI for venue\n",
    "    venue_ref = None\n",
    "    raw_venue = rec.get(\"venueURI\")\n",
    "    if raw_venue:\n",
    "        qid_v = raw_venue if raw_venue.startswith(\"Q\") else raw_venue.rsplit(\"/\", 1)[-1]\n",
    "        venue_ref = WD[qid_v]\n",
    "\n",
    "    # Define internal URIs\n",
    "    event_res = IBSEN[f\"event/{eid}\"]\n",
    "    work_res = IBSEN[f\"work/{wid}\"] if wid else None\n",
    "    venue_res = IBSEN[f\"venue/{vid}\"]\n",
    "\n",
    "    # Add event as a TheaterEvent\n",
    "    g.add((event_res, RDF.type, SCHEMA.TheaterEvent))\n",
    "\n",
    "    # Add event name\n",
    "    name = rec.get(\"eventname_normalized\") or rec.get(\"eventname\")\n",
    "    if name:\n",
    "        g.add((event_res, SCHEMA.name, Literal(name)))\n",
    "\n",
    "    # Add first performance date\n",
    "    first_date = rec.get(\"first_date\")\n",
    "    if first_date:\n",
    "        lex, dt = normalize_date(first_date)\n",
    "        if lex:\n",
    "            lit = Literal(lex, datatype=dt) if dt else Literal(lex)\n",
    "            g.add((event_res, SCHEMA.firstPerformance, lit))\n",
    "\n",
    "    # Link event to work via schema:workPerformed\n",
    "    if work_ref:\n",
    "        g.add((event_res, SCHEMA.workPerformed, work_ref))\n",
    "\n",
    "    # Add event city as location (uses Wikidata QID)\n",
    "    raw_city = rec.get(\"cityURI\")\n",
    "    if raw_city:\n",
    "        qid_c = raw_city if raw_city.startswith(\"Q\") else raw_city.rsplit(\"/\", 1)[-1]\n",
    "        g.add((event_res, SCHEMA.location, WD[qid_c]))\n",
    "\n",
    "    # Add internal identifier for the event\n",
    "    g.add((event_res, DCTERMS.identifier, Literal(eid)))\n",
    "\n",
    "    # Add work (play) as schema:Play\n",
    "    if work_res:\n",
    "        g.add((work_res, RDF.type, SCHEMA.Play))\n",
    "        title = rec.get(\"worktitle\")\n",
    "        if title:\n",
    "            g.add((work_res, SCHEMA.name, Literal(title)))\n",
    "        g.add((work_res, DCTERMS.identifier, Literal(wid)))\n",
    "        if work_ref:\n",
    "            g.add((work_res, SCHEMA.sameAs, work_ref))  # Link to Wikidata\n",
    "\n",
    "    # Add venue as schema:EventVenue\n",
    "    if venue_ref:\n",
    "        g.add((venue_res, SCHEMA.sameAs, venue_ref))  # Link local venue to Wikidata\n",
    "    if venue_res:\n",
    "        g.add((venue_res, RDF.type, SCHEMA.EventVenue))\n",
    "        vname = rec.get(\"venuename\", \"\")\n",
    "        if vname:\n",
    "            g.add((venue_res, SCHEMA.name, Literal(vname)))\n",
    "        g.add((venue_res, DCTERMS.identifier, Literal(vid)))\n",
    "\n",
    "# Serialize graph to Turtle format with manual prefix for wd:\n",
    "ttl_output = g.serialize(format=\"turtle\")\n",
    "ttl_output = \"@prefix wd: <https://www.wikidata.org/entity/> .\\n\" + ttl_output\n",
    "\n",
    "# Save to file\n",
    "output_path.write_text(ttl_output, encoding=\"utf-8\")\n",
    "print(f\"Saved {len(g)} triples to {output_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348771dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "421c1017",
   "metadata": {},
   "source": [
    "# Serialization in RDF/XML\n",
    "\n",
    "The next step is serializing the triplets obtained also in RDF/XML. Serialization changes the RDF graph into a file format that semantic web tools can use to store, share, or read data. While the Turtle file obtained in the previous cell is concise and easy for humans to read and debug, RDF/XML is the original W3C-standard serialization for RDF and remains widely supported by legacy systems, ontology tools, and triplestores. It is more formal, and it integrates easily with XML-based workflows, allows validation using standard XML tools, and ensures maximum interoperability in institutional contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a4726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 30442 triples to:\n",
      "   - C:\\Users\\Cristiano (CC)\\Desktop\\Cristiano-June25\\OsloMet\\Masterstudium i bibliotek- og informasjonsvitenskap - deltid\\MBIB4140 - Metadata og interoperabilitet\\2ndre sjansen\\Ibsenstage_curated\\ibsenstage_triplets.rdf\n"
     ]
    }
   ],
   "source": [
    "# Define output path\n",
    "rdfxml_path = output_dir / \"ibsenstage_triplets.rdf\"\n",
    "\n",
    "# Serialize to RDF/XML (widely supported by semantic web tools and triple stores)\n",
    "rdfxml_output = g.serialize(format=\"xml\")\n",
    "rdfxml_path.write_text(rdfxml_output, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Saved {len(g)} triples to:\")\n",
    "print(f\" - {rdfxml_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c40d09",
   "metadata": {},
   "source": [
    "# Validating\n",
    "\n",
    "The final step is verifying that the RDF file is well-formed. To do so, I will first check if there are any parsing or syntaxt issues locally, then I will make the RDF accessible via an URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RDF/XML is valid.\n"
     ]
    }
   ],
   "source": [
    "#Check if the RDF is well-formed\n",
    "from rdflib import Graph\n",
    "\n",
    "g = Graph()\n",
    "try:\n",
    "    g.parse(\"Ibsenstage_curated/ibsenstage_triplets.rdf\", format=\"xml\")\n",
    "    print(\"RDF/XML is valid.\")\n",
    "except Exception as e:\n",
    "    print(\"RDF/XML is invalid:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4eabe8",
   "metadata": {},
   "source": [
    "The whole project has been uploaded in the repository `MBIB4140_2` on GitHub, and it is publicly available at the link: [https://github.com/Uhyret/MBIB4140_2] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
